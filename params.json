{"name":"Using cuda-stream to concurrent device memory transmission and calculation","tagline":"","body":"### Welcome to GitHub Pages.\r\nSimple introduce of [cuda-stream](http://devblogs.nvidia.com/parallelforall/how-overlap-data-transfers-cuda-cc/)      \r\n\r\nYou can get My code from here:   \r\n```\r\n$ git clone https://github.com/zhxfl/CUDA-CNN.git   \r\n```\r\n\r\n  The first version of my project was only designed for MNIST which is a small and simply dataset, so we copy all the data to device memory.   \r\n  As the size of dataset increase, now I just want to use \"batch size\" of the image on the device. Before every epoch I should copy the data from host memory to device memory, so I need the Cuda-Stream technology to concurrent device memory transmission and calculation. \r\n\r\n### Support or Contact   \r\ncontact zhxfl@mail.ustc.edu.cn, I â€™ll help you sort it out.   ","google":"cuda cnn cuda-stream","note":"Don't delete this file! It's used internally to help with page regeneration."}