{"name":"Using cuda-stream to concurrent device memory transmission and calculation","tagline":"","body":"### Welcome to GitHub Pages.\r\nSimple introduce of [cuda-stream](http://devblogs.nvidia.com/parallelforall/how-overlap-data-transfers-cuda-cc/)      \r\n\r\nYou can get My code from here:   \r\n```\r\n$ git clone https://github.com/zhxfl/CUDA-CNN.git   \r\n```\r\n\r\nThe first version of my project was only designed for MNIST which is a small and simply dataset, so we copy all the data to device memory.  As the size of dataset increase, now I just want to keep \"batch size\" of the image on the device. Before every epoch I should copy the data from host memory to device memory, so I need the Cuda-Stream technology to concurrent device memory transmission and calculation. \r\n\r\nIn order to using cuda-streams, I need double buffers:\r\n```\r\ncuMatrixVector<double>batchImg[2];\r\n/*double buffer for batch images*/\r\n\tfor(int i = 0; i < 2; i ++){\r\n\t\tfor(int j = 0; j < batch; j++){\r\n\t\t\tbatchImg[i].push_back(new cuMatrix<double>(ImgSize + crop, ImgSize + crop, Config::instance()->getChannels()));\r\n\t\t}\r\n\t\tbatchImg[i].toGpu();\r\n\t}\r\n```\r\n\r\n### Support or Contact   \r\ncontact zhxfl@mail.ustc.edu.cn, I â€™ll help you sort it out.   ","google":"cuda cnn cuda-stream","note":"Don't delete this file! It's used internally to help with page regeneration."}